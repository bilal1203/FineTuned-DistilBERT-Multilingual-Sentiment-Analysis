{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% [markdown]\n",
    "# # Fine-tuning DistilBERT for Multilingual Sentiment Analysis\n",
    "\n",
    "# %% [code]\n",
    "# !pip install transformers datasets torch numpy pandas\n",
    "\n",
    "# %% [code]\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n",
    "\n",
    "# %% [code]\n",
    "import os\n",
    "\n",
    "# Set up project directory in Google Drive\n",
    "project_name = \"FineTuned-DistilBERT-Multilingual-Sentiment-Analysis\"\n",
    "base_path = f\"/content/drive/MyDrive/{project_name}\"\n",
    "os.makedirs(base_path, exist_ok=True)\n",
    "\n",
    "# Create subdirectories\n",
    "checkpoints_dir = os.path.join(base_path, \"checkpoints\")\n",
    "logs_dir = os.path.join(base_path, \"logs\")\n",
    "best_model_dir = os.path.join(base_path, \"best_model\")\n",
    "\n",
    "for dir_path in [checkpoints_dir, logs_dir, best_model_dir]:\n",
    "    os.makedirs(dir_path, exist_ok=True)\n",
    "\n",
    "print(f\"Project directory created at: {base_path}\")\n",
    "\n",
    "# %% [code]\n",
    "# !git clone https://github.com/your-username/FineTuned-DistilBERT-Multilingual-Sentiment-Analysis.git\n",
    "# %cd FineTuned-DistilBERT-Multilingual-Sentiment-Analysis\n",
    "\n",
    "# %% [code]\n",
    "import torch\n",
    "from src.train import train_model, get_training_args\n",
    "from src.evaluate import run_evaluation\n",
    "\n",
    "# %% [code]\n",
    "# Check if GPU is available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# %% [code]\n",
    "# Modify training arguments\n",
    "training_args = get_training_args()\n",
    "training_args.output_dir = checkpoints_dir\n",
    "training_args.logging_dir = logs_dir\n",
    "\n",
    "# Train the model\n",
    "print(\"Starting training...\")\n",
    "trainer, test_dataset = train_model(training_args)\n",
    "\n",
    "# Save the best model\n",
    "print(\"Saving the best model...\")\n",
    "trainer.save_model(best_model_dir)\n",
    "trainer.tokenizer.save_pretrained(best_model_dir)\n",
    "\n",
    "# %% [code]\n",
    "# Run evaluation\n",
    "print(\"Running evaluation...\")\n",
    "run_evaluation(trainer, test_dataset)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
